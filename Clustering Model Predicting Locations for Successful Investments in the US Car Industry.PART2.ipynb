{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Capstone Project: Business Problem</h5>\n",
    "by Frantzdy Hervé\n",
    "<h3>Introduction</h3> \n",
    "The car industry has been booming recently in the United States [Source: Investopedia](https://www.investopedia.com/articles/pf/12/auto-industry.asp#:~:text=The%20U.S.%20economy%20was%20booming,million%20new%20cars%20were%20sold.&text=Among%20the%20more%20notable%20early,difficult%20recession%20of%202007%2D2008.). The tendency now favors more and more electric vehicles as they are viewed to be more environmentally-friendly and their design gives a feel of vehicles of the future. An automaker, namely Tesla, has particularly grown rapidly and its sales are projected to only increase in the future [Source: History of the electric vehicles](https://www.energy.gov/articles/history-electric-car#:~:text=First%20Crude%20Electric%20Vehicle%20Is,an%20English%20inventor%20in%201884). The ambitious investor might also be wondering:'What is in it for me?'\n",
    "\n",
    "If electric vehicles seem to be very attractive to the consumer, their price and the infrastructure that is required to facilitate their charging or even their construction do not seem to be particularly approachable. The latter seems to be the most challenging aspect of it all when one considers the fact that electric vehicles are almost completely different to the traditional vehicles when it comes to their engine outlook, their transmission system, their source of power, and the highly advanced technology needed for their computing wiring. In order to fathom how difficult these challenges are, we could preview what range of obstacles Tesla has had to face, (and continue to) just a few years ago to produce its cars from scratch in a gigafactory. Based on the poor financial performance they had just 3 years ago, there were some predictions indicating that they would not survive in the market for long. However, the persistence of its ceo has proved to pay off as he fafced all the challenges head on and planned accordingly. Today, this segment of the car industry in the US seems to be only promising and that might be what any investor willing to find a niche for highly profitable investments would be interested in.\n",
    "\n",
    "<h3>Business Problem</h3>\n",
    "As mentioned earlier, the electric vehicles represent a niche which requires massive investment to build the infrastructure needed. [Source: Estimates for building a charging station](https://www.homeadvisor.com/cost/garages/install-an-electric-vehicle-charging-station/#:~:text=The%20national%20average%20for%20installing,median%20cost%20is%20%24731%20each). This obstacle could be largely offset, though, by the financial gain any smart investment in the electric car industry might yield. Based on the most pessimistic predictions, the traditional combustion engine will go extinct in about ten years while the increase in consumer's demand for electric cars and auto parts will continue at a staggering rate of 21% [Source: Booming demand for electric vehicles](https://www.marketsandmarkets.com/Market-Reports/electric-vehicle-market-209371461.html). The key to grapple here is that the demand is not uniform in the US, all the states are not equal when it comes to growth in any sector. And, specifically, because of disparity in terms of the growth in the population by state and by urban area, job opportunities, and income per capita, one must be very cautious when targetting locations for their investment in said sector. As such, the need to identify the states and the cities where the demand for reliable transportation would be the most promising is then a good place to start. And this factor alone could be a good strategy to mobilize the funds needed as the early investors might break even from their investment in just a couple of quarters. However, the question remains, in what urban areas the demand for electric vehicles might be the highest? What states would then see these demands manifested the highest?\n",
    "\n",
    "<h3>What we propose</h3>\n",
    "The following lines will provide a comprehensive approach to predict the states where the demand for cars and auto parts will continue to grow and identify the urban areas where the population seems to be the most active. This solution is inspired by the data provided from the US Bureau of Economic Analysis (BEA) and the platform provided by Foursquare to locate areas where most venues are frequented. We will then leverage data using the BEA's API guidance and the well-structured platform designed by Foursquare. \n",
    "<dl>\n",
    "  <dt>Our approach is two-fold:</dt>\n",
    "  <dd>1. First, we pull data from the BEA's website related to the production level in each US state, the population, the income per capita and the consumer's spending for the past 11 years[^1]. This would allow us to use enough data that would increase the model accuracy in terms of predicting the 5 states with the highest demand for cars and auto parts in the years to come;</dd>\n",
    "  <dd>2. Finally, we use the Foursquare platform to locate those urban areas where the population seems to be the most active from the states previously identified;</dd>\n",
    "  This submission answers the second question of the assignment which is the presentation of the data section that we will use for the final project.\n",
    "   </dl>\n",
    "   \n",
    "[^1]: The Consumer's consumption spending for cars and auto parts and the income per capita were not available for the year 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Presentation of the scraping techniques used to leverage data from the BEA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Folium installed\n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import requests # library to handle requests\n",
    "import pandas as pd # library for data analsysis\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "import random # library for random number generation\n",
    "\n",
    "!conda install -c conda-forge geopy --yes \n",
    "from geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n",
    "\n",
    "# libraries for displaying images\n",
    "from IPython.display import Image \n",
    "from IPython.core.display import HTML \n",
    "    \n",
    "# tranforming json file into a pandas dataframe library\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium # plotting library\n",
    "\n",
    "print('Folium installed')\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API request to the bureau of economic analysis's website\n",
    "#Model for metadata request of list of available datasets:(http://apps.bea.gov/api/data?&UserID=Your-36CharacterKey&method=GETDATASETLIST&ResultFormat=JSON)\n",
    "API_key='866C34B1-B3F1-4AB6-BD3A-C3F9D73FCC1D'\n",
    "Method = 'GetData' #'GetParameterValues'\n",
    "Result_format = 'JSON'\n",
    "DataSetName ='NIUnderlyingDetail'\n",
    "TableName ='U70205S' #reference for auto and Truck Unit Sales, Production, Inventories, Expenditures and Price\n",
    "ParameterName = 'TableName'\n",
    "Frequency = 'M'\n",
    "Year_int = 2019\n",
    "Year = str(Year_int)\n",
    "GeoFips_C = 'COUNTY'\n",
    "State = 'All'\n",
    "Industry = 'All'\n",
    "\n",
    "DN_Regional = 'Regional' # LineCode, TN, and GeoFIPS required\n",
    "LineCode = 1 # or other digit?\n",
    "TN_GDP_State = 'SQGDP9' # or 'SAGDP2S'\n",
    "TN_Pop = 'SAINC51'\n",
    "TN_consSpending = 'SAEXP2'\n",
    "TN_IncPerCapita = 'CAINC1'\n",
    "LC_GDP = 1\n",
    "\n",
    "url_GDP = {'GDP_2019' : '', 'GDP_2018' : '', 'GDP_2017' : '', 'GDP_2016' : '', 'GDP_2015' : '', 'GDP_2014' : '', 'GDP_2013' : '', 'GDP_2012' : '',\n",
    "'GDP_2011' : '', 'GDP_2010' : '', 'GDP_2009' : ''}\n",
    "\n",
    "GDP_dict = {'GDP_2019' : '', 'GDP_2018' : '', 'GDP_2017' : '', 'GDP_2016' : '', 'GDP_2015' : '', 'GDP_2014' : '', 'GDP_2013' : '', 'GDP_2012' : '',\n",
    "'GDP_2011' : '', 'GDP_2010' : '', 'GDP_2009' : ''}\n",
    "\n",
    "GeoFips = 'STATE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 11):\n",
    "    Year = str(Year_int - i)\n",
    "    url_GDP[i] = 'http://apps.bea.gov/api/data?&UserID={}&method={}&DataSetName=Regional&TableName={}&LineCode={}&Year={}&GeoFips={}&ResultFormat={}'.format(\n",
    "                  API_key, Method, TN_GDP_State, LC_GDP, Year, GeoFips, Result_format)\n",
    "    GDP_dict[i] = requests.get(url_GDP[i]).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Data Wrangling to obtain csv files that contain the information needed for further analysis.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>GeoFips</th>\n",
       "      <th>GeoName</th>\n",
       "      <th>TimePeriod</th>\n",
       "      <th>CL_UNIT</th>\n",
       "      <th>UNIT_MULT</th>\n",
       "      <th>DataValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SQGDP9-1</td>\n",
       "      <td>00000</td>\n",
       "      <td>United States</td>\n",
       "      <td>2009Q1</td>\n",
       "      <td>Millions of chained 2012 dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>15,155,940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SQGDP9-1</td>\n",
       "      <td>00000</td>\n",
       "      <td>United States</td>\n",
       "      <td>2009Q2</td>\n",
       "      <td>Millions of chained 2012 dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>15,134,117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SQGDP9-1</td>\n",
       "      <td>00000</td>\n",
       "      <td>United States</td>\n",
       "      <td>2009Q3</td>\n",
       "      <td>Millions of chained 2012 dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>15,189,222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SQGDP9-1</td>\n",
       "      <td>00000</td>\n",
       "      <td>United States</td>\n",
       "      <td>2009Q4</td>\n",
       "      <td>Millions of chained 2012 dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>15,356,058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SQGDP9-1</td>\n",
       "      <td>01000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2009Q1</td>\n",
       "      <td>Millions of chained 2012 dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>177,770.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Code GeoFips        GeoName TimePeriod  \\\n",
       "0  SQGDP9-1   00000  United States     2009Q1   \n",
       "1  SQGDP9-1   00000  United States     2009Q2   \n",
       "2  SQGDP9-1   00000  United States     2009Q3   \n",
       "3  SQGDP9-1   00000  United States     2009Q4   \n",
       "4  SQGDP9-1   01000        Alabama     2009Q1   \n",
       "\n",
       "                            CL_UNIT UNIT_MULT     DataValue  \n",
       "0  Millions of chained 2012 dollars         6  15,155,940.0  \n",
       "1  Millions of chained 2012 dollars         6  15,134,117.0  \n",
       "2  Millions of chained 2012 dollars         6  15,189,222.0  \n",
       "3  Millions of chained 2012 dollars         6  15,356,058.0  \n",
       "4  Millions of chained 2012 dollars         6     177,770.1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the GDP data for 11 years\n",
    "GDP_2019_0 = GDP_dict[0]\n",
    "GDP_2019_0j = GDP_2019_0['BEAAPI']['Results']['Data']\n",
    "GDP_2019_0df = json_normalize(GDP_2019_0j)\n",
    "GDP_2019_0df.to_csv('GDP_2019_0df.csv')\n",
    "\n",
    "GDP_2018_0 = GDP_dict[1]\n",
    "GDP_2018_0j = GDP_2018_0['BEAAPI']['Results']['Data']\n",
    "GDP_2018_0df = json_normalize(GDP_2018_0j)\n",
    "GDP_2018_0df.to_csv('GDP_2018_0df.csv')\n",
    "\n",
    "GDP_2017_0 = GDP_dict[2]\n",
    "GDP_2017_0j = GDP_2017_0['BEAAPI']['Results']['Data']\n",
    "GDP_2017_0df = json_normalize(GDP_2017_0j)\n",
    "GDP_2017_0df.to_csv('GDP_2017_0df.csv')\n",
    "\n",
    "GDP_2016_0 = GDP_dict[3]\n",
    "GDP_2016_0j = GDP_2016_0['BEAAPI']['Results']['Data']\n",
    "GDP_2016_0df = json_normalize(GDP_2016_0j)\n",
    "GDP_2016_0df.to_csv('GDP_2016_0df.csv')\n",
    "\n",
    "GDP_2015_0 = GDP_dict[4]\n",
    "GDP_2015_0j = GDP_2015_0['BEAAPI']['Results']['Data']\n",
    "GDP_2015_0df = json_normalize(GDP_2015_0j)\n",
    "GDP_2015_0df.to_csv('GDP_2015_0df.csv')\n",
    "\n",
    "GDP_2014_0 = GDP_dict[5]\n",
    "GDP_2014_0j = GDP_2014_0['BEAAPI']['Results']['Data']\n",
    "GDP_2014_0df = json_normalize(GDP_2014_0j)\n",
    "GDP_2014_0df.to_csv('GDP_2014_0df.csv')\n",
    "\n",
    "GDP_2013_0 = GDP_dict[6]\n",
    "GDP_2013_0j = GDP_2013_0['BEAAPI']['Results']['Data']\n",
    "GDP_2013_0df = json_normalize(GDP_2013_0j)\n",
    "GDP_2013_0df.to_csv('GDP_2013_0df.csv')\n",
    "\n",
    "GDP_2012_0 = GDP_dict[7]\n",
    "GDP_2012_0j = GDP_2012_0['BEAAPI']['Results']['Data']\n",
    "GDP_2012_0df = json_normalize(GDP_2012_0j)\n",
    "GDP_2012_0df.to_csv('GDP_2012_0df.csv')\n",
    "\n",
    "GDP_2011_0 = GDP_dict[8]\n",
    "GDP_2011_0j = GDP_2011_0['BEAAPI']['Results']['Data']\n",
    "GDP_2011_0df = json_normalize(GDP_2011_0j)\n",
    "GDP_2011_0df.to_csv('GDP_2011_0df.csv')\n",
    "\n",
    "GDP_2010_0 = GDP_dict[9]\n",
    "GDP_2010_0j = GDP_2010_0['BEAAPI']['Results']['Data']\n",
    "GDP_2010_0df = json_normalize(GDP_2010_0j)\n",
    "GDP_2010_0df.to_csv('GDP_2010_0df.csv')\n",
    "\n",
    "GDP_2009_0 = GDP_dict[10]\n",
    "GDP_2009_0j = GDP_2009_0['BEAAPI']['Results']['Data']\n",
    "GDP_2009_0df = json_normalize(GDP_2009_0j)\n",
    "GDP_2009_0df.to_csv('GDP_2009_0df.csv')\n",
    "GDP_2009_0df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pop = {'POP_2019' : '', 'POP_2018' : '', 'POP_2017' : '', 'POP_2016' : '', 'POP_2015' : '', 'POP_2014' : '', 'POP_2013' : '', 'GDP_2012' : '',\n",
    "'POP_2011' : '', 'POP_2010' : '', 'POP_2009' : ''}\n",
    "\n",
    "POP_dict = {'POP_2019' : '', 'POP_2018' : '', 'POP_2017' : '', 'POP_2016' : '', 'POP_2015' : '', 'POP_2014' : '', 'POP_2013' : '', 'GDP_2012' : '',\n",
    "'POP_2011' : '', 'POP_2010' : '', 'POP_2009' : ''}\n",
    "\n",
    "LC_Pop = 52 # Could add 51 too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 11):\n",
    "    Year = str(Year_int - i)\n",
    "    url_pop[i] = 'http://apps.bea.gov/api/data?&UserID={}&method={}&DataSetName=Regional&TableName={}&LineCode={}&Year={}&GeoFips={}&ResultFormat={}'.format(\n",
    "                  API_key, Method, TN_Pop, LC_Pop, Year, GeoFips, Result_format)\n",
    "    POP_dict[i] = requests.get(url_pop[i]).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>GeoFips</th>\n",
       "      <th>GeoName</th>\n",
       "      <th>TimePeriod</th>\n",
       "      <th>CL_UNIT</th>\n",
       "      <th>UNIT_MULT</th>\n",
       "      <th>DataValue</th>\n",
       "      <th>NoteRef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SAINC51-52</td>\n",
       "      <td>00000</td>\n",
       "      <td>United States *</td>\n",
       "      <td>2009</td>\n",
       "      <td>Number of persons</td>\n",
       "      <td>0</td>\n",
       "      <td>306,771,529</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SAINC51-52</td>\n",
       "      <td>01000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2009</td>\n",
       "      <td>Number of persons</td>\n",
       "      <td>0</td>\n",
       "      <td>4,757,938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SAINC51-52</td>\n",
       "      <td>02000</td>\n",
       "      <td>Alaska *</td>\n",
       "      <td>2009</td>\n",
       "      <td>Number of persons</td>\n",
       "      <td>0</td>\n",
       "      <td>698,895</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SAINC51-52</td>\n",
       "      <td>04000</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2009</td>\n",
       "      <td>Number of persons</td>\n",
       "      <td>0</td>\n",
       "      <td>6,343,154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SAINC51-52</td>\n",
       "      <td>05000</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2009</td>\n",
       "      <td>Number of persons</td>\n",
       "      <td>0</td>\n",
       "      <td>2,896,843</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Code GeoFips          GeoName TimePeriod            CL_UNIT  \\\n",
       "0  SAINC51-52   00000  United States *       2009  Number of persons   \n",
       "1  SAINC51-52   01000          Alabama       2009  Number of persons   \n",
       "2  SAINC51-52   02000         Alaska *       2009  Number of persons   \n",
       "3  SAINC51-52   04000          Arizona       2009  Number of persons   \n",
       "4  SAINC51-52   05000         Arkansas       2009  Number of persons   \n",
       "\n",
       "  UNIT_MULT    DataValue NoteRef  \n",
       "0         0  306,771,529       *  \n",
       "1         0    4,757,938     NaN  \n",
       "2         0      698,895       *  \n",
       "3         0    6,343,154     NaN  \n",
       "4         0    2,896,843     NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POP_2019_0 = POP_dict[0]\n",
    "POP_2019_0j = POP_2019_0['BEAAPI']['Results']['Data']\n",
    "POP_2019_0df = json_normalize(POP_2019_0j)\n",
    "POP_2019_0df.to_csv('POP_2019_0df.csv')\n",
    "\n",
    "POP_2018_0 = POP_dict[1]\n",
    "POP_2018_0j = POP_2018_0['BEAAPI']['Results']['Data']\n",
    "POP_2018_0df = json_normalize(POP_2018_0j)\n",
    "POP_2018_0df.to_csv('POP_2018_0df.csv')\n",
    "\n",
    "POP_2017_0 = POP_dict[2]\n",
    "POP_2017_0j = POP_2017_0['BEAAPI']['Results']['Data']\n",
    "POP_2017_0df = json_normalize(POP_2017_0j)\n",
    "POP_2017_0df.to_csv('POP_2017_0df.csv')\n",
    "\n",
    "POP_2016_0 = POP_dict[3]\n",
    "POP_2016_0j = POP_2016_0['BEAAPI']['Results']['Data']\n",
    "POP_2016_0df = json_normalize(POP_2016_0j)\n",
    "POP_2016_0df.to_csv('POP_2016_0df.csv')\n",
    "\n",
    "POP_2015_0 = POP_dict[4]\n",
    "POP_2015_0j = POP_2015_0['BEAAPI']['Results']['Data']\n",
    "POP_2015_0df = json_normalize(POP_2015_0j)\n",
    "POP_2015_0df.to_csv('POP_2015_0df.csv')\n",
    "\n",
    "POP_2014_0 = POP_dict[5]\n",
    "POP_2014_0j = POP_2014_0['BEAAPI']['Results']['Data']\n",
    "POP_2014_0df = json_normalize(POP_2014_0j)\n",
    "POP_2014_0df.to_csv('POP_2014_0df.csv')\n",
    "\n",
    "POP_2013_0 = POP_dict[6]\n",
    "POP_2013_0j = POP_2013_0['BEAAPI']['Results']['Data']\n",
    "POP_2013_0df = json_normalize(POP_2013_0j)\n",
    "POP_2013_0df.to_csv('POP_2013_0df.csv')\n",
    "\n",
    "POP_2012_0 = POP_dict[7]\n",
    "POP_2012_0j = POP_2012_0['BEAAPI']['Results']['Data']\n",
    "POP_2012_0df = json_normalize(POP_2012_0j)\n",
    "POP_2012_0df.to_csv('POP_2012_0df.csv')\n",
    "\n",
    "POP_2011_0 = POP_dict[8]\n",
    "POP_2011_0j = POP_2011_0['BEAAPI']['Results']['Data']\n",
    "POP_2011_0df = json_normalize(POP_2011_0j)\n",
    "POP_2011_0df.to_csv('POP_2011_0df.csv')\n",
    "\n",
    "POP_2010_0 = POP_dict[9]\n",
    "POP_2010_0j = POP_2010_0['BEAAPI']['Results']['Data']\n",
    "POP_2010_0df = json_normalize(POP_2010_0j)\n",
    "POP_2010_0df.to_csv('POP_2010_0df.csv')\n",
    "\n",
    "POP_2009_0 = POP_dict[10]\n",
    "POP_2009_0j = POP_2009_0['BEAAPI']['Results']['Data']\n",
    "POP_2009_0df = json_normalize(POP_2009_0j)\n",
    "POP_2009_0df.to_csv('POP_2009_0df.csv')\n",
    "POP_2009_0df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_cons = {'CON_2019' : '', 'CON_2018' : '', 'CON_2017' : '', 'CON_2016' : '', 'CON_2015' : '', 'CON_2014' : '', 'CON_2013' : '', 'GDP_2012' : '',\n",
    "'CON_2011' : '', 'CON_2010' : '', 'CON_2009' : ''}\n",
    "\n",
    "CONS_dict = {'CON_2019' : '', 'CON_2018' : '', 'CON_2017' : '', 'CON_2016' : '', 'CON_2015' : '', 'CON_2014' : '', 'CON_2013' : '', 'GDP_2012' : '',\n",
    "'CON_2011' : '', 'CON_2010' : '', 'CON_2009' : ''}\n",
    "\n",
    "LC_ConsSpend = 1 # motor vehicles and parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 11):\n",
    "    Year = str(Year_int - i)\n",
    "    url_cons[i] = 'http://apps.bea.gov/api/data?&UserID={}&method={}&DataSetName=Regional&TableName={}&LineCode={}&Year={}&GeoFips={}&ResultFormat={}'.format(\n",
    "                  API_key, Method, TN_consSpending, LC_ConsSpend, Year, GeoFips, Result_format)\n",
    "    CONS_dict[i] = requests.get(url_cons[i]).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>GeoFips</th>\n",
       "      <th>GeoName</th>\n",
       "      <th>TimePeriod</th>\n",
       "      <th>CL_UNIT</th>\n",
       "      <th>UNIT_MULT</th>\n",
       "      <th>DataValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>00000</td>\n",
       "      <td>United States</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>32,054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>01000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>26,587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>02000</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>38,355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>04000</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>28,596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>05000</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>25,678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Code GeoFips        GeoName TimePeriod  CL_UNIT UNIT_MULT DataValue\n",
       "0  SAEXP2-1   00000  United States       2009  Dollars         0    32,054\n",
       "1  SAEXP2-1   01000        Alabama       2009  Dollars         0    26,587\n",
       "2  SAEXP2-1   02000         Alaska       2009  Dollars         0    38,355\n",
       "3  SAEXP2-1   04000        Arizona       2009  Dollars         0    28,596\n",
       "4  SAEXP2-1   05000       Arkansas       2009  Dollars         0    25,678"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONS_2018_0 = CONS_dict[1]\n",
    "CONS_2018_0j = CONS_2018_0['BEAAPI']['Results']['Data']\n",
    "CONS_2018_0df = json_normalize(CONS_2018_0j)\n",
    "CONS_2018_0df.to_csv('CONS_2018_0df.csv')\n",
    "\n",
    "CONS_2017_0 = CONS_dict[2]\n",
    "CONS_2017_0j = CONS_2017_0['BEAAPI']['Results']['Data']\n",
    "CONS_2017_0df = json_normalize(CONS_2017_0j)\n",
    "CONS_2017_0df.to_csv('CONS_2017_0df.csv')\n",
    "\n",
    "CONS_2016_0 = CONS_dict[3]\n",
    "CONS_2016_0j = CONS_2016_0['BEAAPI']['Results']['Data']\n",
    "CONS_2016_0df = json_normalize(CONS_2016_0j)\n",
    "CONS_2016_0df.to_csv('CONS_2016_0df.csv')\n",
    "\n",
    "CONS_2015_0 = CONS_dict[4]\n",
    "CONS_2015_0j = CONS_2015_0['BEAAPI']['Results']['Data']\n",
    "CONS_2015_0df = json_normalize(CONS_2015_0j)\n",
    "CONS_2015_0df.to_csv('CONS_2015_0df.csv')\n",
    "\n",
    "CONS_2014_0 = CONS_dict[5]\n",
    "CONS_2014_0j = CONS_2014_0['BEAAPI']['Results']['Data']\n",
    "CONS_2014_0df = json_normalize(CONS_2014_0j)\n",
    "CONS_2014_0df.to_csv('CONS_2014_0df.csv')\n",
    "\n",
    "CONS_2013_0 = CONS_dict[6]\n",
    "CONS_2013_0j = CONS_2013_0['BEAAPI']['Results']['Data']\n",
    "CONS_2013_0df = json_normalize(CONS_2013_0j)\n",
    "CONS_2013_0df.to_csv('CONS_2013_0df.csv')\n",
    "\n",
    "CONS_2012_0 = CONS_dict[7]\n",
    "CONS_2012_0j = CONS_2012_0['BEAAPI']['Results']['Data']\n",
    "CONS_2012_0df = json_normalize(CONS_2012_0j)\n",
    "CONS_2012_0df.to_csv('CONS_2012_0df.csv')\n",
    "\n",
    "CONS_2011_0 = CONS_dict[8]\n",
    "CONS_2011_0j = CONS_2011_0['BEAAPI']['Results']['Data']\n",
    "CONS_2011_0df = json_normalize(CONS_2011_0j)\n",
    "CONS_2011_0df.to_csv('CONS_2011_0df.csv')\n",
    "\n",
    "CONS_2010_0 = CONS_dict[9]\n",
    "CONS_2010_0j = CONS_2010_0['BEAAPI']['Results']['Data']\n",
    "CONS_2010_0df = json_normalize(CONS_2010_0j)\n",
    "CONS_2010_0df.to_csv('CONS_2010_0df.csv')\n",
    "\n",
    "CONS_2009_0 = CONS_dict[10]\n",
    "CONS_2009_0j = CONS_2009_0['BEAAPI']['Results']['Data']\n",
    "CONS_2009_0df = json_normalize(CONS_2009_0j)\n",
    "CONS_2009_0df.to_csv('CONS_2009_0df.csv')\n",
    "CONS_2009_0df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We note that data for consumer's consumption spending for cars and auto parts was not available for the year 2019 on the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_inc = {'INC_2019' : '', 'INC_2018' : '', 'INC_2017' : '', 'INC_2016' : '', 'INC_2015' : '', 'INC_2014' : '', 'INC_2013' : '', 'GDP_2012' : '',\n",
    "'INC_2011' : '', 'INC_2010' : '', 'INC_2009' : ''}\n",
    "\n",
    "INC_dict = {'INC_2019' : '', 'INC_2018' : '', 'INC_2017' : '', 'INC_2016' : '', 'INC_2015' : '', 'INC_2014' : '', 'INC_2013' : '', 'GDP_2012' : '',\n",
    "'INC_2011' : '', 'INC_2010' : '', 'INC_2009' : ''}\n",
    "\n",
    "LC_inc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 11):\n",
    "    Year = str(Year_int - i)\n",
    "    url_inc[i] = 'http://apps.bea.gov/api/data?&UserID={}&method={}&DataSetName=Regional&TableName={}&LineCode={}&Year={}&GeoFips={}&ResultFormat={}'.format(\n",
    "                  API_key, Method, TN_IncPerCapita, LC_inc, Year, GeoFips, Result_format)\n",
    "    INC_dict[i] = requests.get(url_cons[i]).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>GeoFips</th>\n",
       "      <th>GeoName</th>\n",
       "      <th>TimePeriod</th>\n",
       "      <th>CL_UNIT</th>\n",
       "      <th>UNIT_MULT</th>\n",
       "      <th>DataValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>00000</td>\n",
       "      <td>United States</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>32,054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>01000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>26,587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>02000</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>38,355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>04000</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>28,596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SAEXP2-1</td>\n",
       "      <td>05000</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2009</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>0</td>\n",
       "      <td>25,678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Code GeoFips        GeoName TimePeriod  CL_UNIT UNIT_MULT DataValue\n",
       "0  SAEXP2-1   00000  United States       2009  Dollars         0    32,054\n",
       "1  SAEXP2-1   01000        Alabama       2009  Dollars         0    26,587\n",
       "2  SAEXP2-1   02000         Alaska       2009  Dollars         0    38,355\n",
       "3  SAEXP2-1   04000        Arizona       2009  Dollars         0    28,596\n",
       "4  SAEXP2-1   05000       Arkansas       2009  Dollars         0    25,678"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INC_2018_0 = INC_dict[1]\n",
    "INC_2018_0j = INC_2018_0['BEAAPI']['Results']['Data']\n",
    "INC_2018_0df = json_normalize(INC_2018_0j)\n",
    "INC_2018_0df.to_csv('INC_2018_0df.csv')\n",
    "\n",
    "INC_2017_0 = INC_dict[2]\n",
    "INC_2017_0j = INC_2017_0['BEAAPI']['Results']['Data']\n",
    "INC_2017_0df = json_normalize(INC_2017_0j)\n",
    "INC_2017_0df.to_csv('INC_2017_0df.csv')\n",
    "\n",
    "INC_2016_0 = INC_dict[3]\n",
    "INC_2016_0j = INC_2016_0['BEAAPI']['Results']['Data']\n",
    "INC_2016_0df = json_normalize(INC_2016_0j)\n",
    "INC_2016_0df.to_csv('INC_2016_0df.csv')\n",
    "\n",
    "INC_2015_0 = INC_dict[4]\n",
    "INC_2015_0j = INC_2015_0['BEAAPI']['Results']['Data']\n",
    "INC_2015_0df = json_normalize(INC_2015_0j)\n",
    "INC_2015_0df.to_csv('INC_2015_0df.csv')\n",
    "\n",
    "INC_2014_0 = INC_dict[5]\n",
    "INC_2014_0j = INC_2014_0['BEAAPI']['Results']['Data']\n",
    "INC_2014_0df = json_normalize(INC_2014_0j)\n",
    "INC_2014_0df.to_csv('INC_2014_0df.csv')\n",
    "\n",
    "INC_2013_0 = INC_dict[6]\n",
    "INC_2013_0j = INC_2013_0['BEAAPI']['Results']['Data']\n",
    "INC_2013_0df = json_normalize(INC_2013_0j)\n",
    "INC_2013_0df.to_csv('INC_2013_0df.csv')\n",
    "\n",
    "INC_2012_0 = INC_dict[7]\n",
    "INC_2012_0j = INC_2012_0['BEAAPI']['Results']['Data']\n",
    "INC_2012_0df = json_normalize(INC_2012_0j)\n",
    "INC_2012_0df.to_csv('INC_2012_0df.csv')\n",
    "\n",
    "INC_2011_0 = INC_dict[8]\n",
    "INC_2011_0j = INC_2011_0['BEAAPI']['Results']['Data']\n",
    "INC_2011_0df = json_normalize(INC_2011_0j)\n",
    "INC_2011_0df.to_csv('INC_2011_0df.csv')\n",
    "\n",
    "INC_2010_0 = INC_dict[9]\n",
    "INC_2010_0j = INC_2010_0['BEAAPI']['Results']['Data']\n",
    "INC_2010_0df = json_normalize(INC_2010_0j)\n",
    "INC_2010_0df.to_csv('INC_2010_0df.csv')\n",
    "\n",
    "INC_2009_0 = INC_dict[10]\n",
    "INC_2009_0j = INC_2009_0['BEAAPI']['Results']['Data']\n",
    "INC_2009_0df = json_normalize(INC_2009_0j)\n",
    "INC_2009_0df.to_csv('INC_2009_0df.csv')\n",
    "INC_2009_0df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We note that data for consumer's consumption spending for cars and auto parts was not available for the year 2019 on the site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Process of scraping Foursquare for specific locations within a major state</h3>\n",
    "<dl>\n",
    "  <dt>Important note:</dt>\n",
    "    <dd> It is important to note that the data once obtained we will go ahead and analyze to discover any missing information or other formatting problems. Then we will try to see if there is any correlation between the different variables such as population growth and income per capita for instance. Once the data is ready, we will estimate a clustering model in order to predict the per capita consumer's spending for cars and auto parts. The model once built, we will then select the 5 states where the population growth is the highest. </dd>\n",
    "    </dl>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'ZYOAVPSPIOIKRXIJGJ1EB02IKOQZW25JJ5JO04H1NSUAZM3Y' # your Foursquare ID\n",
    "CLIENT_SECRET = 'UNLEX3EMVZDKCDXS5XGGT1I0MKRPKDHCU0NWUPVEBHAAVDUD' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The geograpical coordinate of Detroit City, MI are 42.3315509, -83.0466403.\n"
     ]
    }
   ],
   "source": [
    "#The city of Detroit is used here just as an illustration of how data would be extracted from Foursquare in further selecting major \n",
    "#urban areas\n",
    "\n",
    "address = 'Detroit City, MI'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"Detroit\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Detroit City, MI are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=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 onload=\"this.contentDocument.open();this.contentDocument.write(atob(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x21bb49cdf88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create map of Detroit using latitude and longitude values for a clearer view of its main urban areas\n",
    "map_Detroit = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "map_Detroit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.foursquare.com/v2/venues/explore?&client_id=ZYOAVPSPIOIKRXIJGJ1EB02IKOQZW25JJ5JO04H1NSUAZM3Y&client_secret=UNLEX3EMVZDKCDXS5XGGT1I0MKRPKDHCU0NWUPVEBHAAVDUD&v=20180605&ll=42.3315509,-83.0466403&radius=1000&limit=100'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If Detroit is selected in our model, we will use the Foursquare app to leverage data for identifying its most populous \n",
    "#locations\n",
    "\n",
    "LIMIT = 100 # limit of number of venues returned by Foursquare API\n",
    "\n",
    "radius = 1000 # define radius in meters\n",
    " # create URL\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    latitude, \n",
    "    longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "url # display URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_detCity = requests.get(url).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Campus Martius</td>\n",
       "      <td>Park</td>\n",
       "      <td>42.331575</td>\n",
       "      <td>-83.046598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Avalon Cafe and Bakery</td>\n",
       "      <td>Café</td>\n",
       "      <td>42.332834</td>\n",
       "      <td>-83.047694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Texas de Brazil</td>\n",
       "      <td>Steakhouse</td>\n",
       "      <td>42.332293</td>\n",
       "      <td>-83.046711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dime Store</td>\n",
       "      <td>American Restaurant</td>\n",
       "      <td>42.331039</td>\n",
       "      <td>-83.047734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Parc</td>\n",
       "      <td>American Restaurant</td>\n",
       "      <td>42.331564</td>\n",
       "      <td>-83.046700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name           categories        lat        lng\n",
       "0          Campus Martius                 Park  42.331575 -83.046598\n",
       "1  Avalon Cafe and Bakery                 Café  42.332834 -83.047694\n",
       "2         Texas de Brazil           Steakhouse  42.332293 -83.046711\n",
       "3              Dime Store  American Restaurant  42.331039 -83.047734\n",
       "4                    Parc  American Restaurant  42.331564 -83.046700"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering the data to select only information of interest\n",
    "venues_detCity = results_detCity['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues_detCity = json_normalize(venues_detCity) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues_detCity =nearby_venues_detCity.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues_detCity['venue.categories'] = nearby_venues_detCity.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues_detCity.columns = [col.split(\".\")[-1] for col in nearby_venues_detCity.columns]\n",
    "\n",
    "nearby_venues_detCity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 venues were returned by Foursquare.\n"
     ]
    }
   ],
   "source": [
    "#Calculation of the number of venues recorded on the platform\n",
    "NumVenues_DetroitCity = nearby_venues_detCity.shape[0]\n",
    "print('{} venues were returned by Foursquare.'.format(NumVenues_DetroitCity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Conclusion</h5>\n",
    "From the comparison between several major agglomerations within a state selected from the model, we will then further select the three urban areas with the highest numbers of venues. This would be an indication of not only the region is populous but also that economic activities are increasing in said locations. This would then suggest that people would be very likely to buy a car or rely on public transportation systems to go about their activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
